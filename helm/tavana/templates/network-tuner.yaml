{{- if .Values.networkTuning.enabled }}
# ============================================================================
# Network Tuning DaemonSet - TCP BBR Congestion Control
# ============================================================================
#
# This DaemonSet applies high-performance network kernel parameters to all nodes
# in the cluster. Based on ESnet (DOE) and Google research:
#
# TCP BBR Benefits:
# - 10x performance improvement on paths with packet loss
# - Avoids bufferbloat by not filling bottleneck buffers
# - Better throughput for high-bandwidth, high-latency connections
#
# Buffer Sizing:
# - Increased TCP buffer sizes for 10G+ networks
# - Larger connection tracking for many concurrent connections
#
# References:
# - https://fasterdata.es.net/host-tuning/linux
# - https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster
# - https://wiki.geant.org/pages/viewpage.action?pageId=121340614
#
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: network-tuner
  namespace: {{ .Values.global.namespace }}
  labels:
    app: tavana-network-tuner
    {{- include "tavana.labels" . | nindent 4 }}
spec:
  selector:
    matchLabels:
      app: tavana-network-tuner
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: tavana-network-tuner
    spec:
      # Run on all nodes including control plane if needed
      tolerations:
        - operator: Exists
      {{- if .Values.networkTuning.nodeSelector }}
      nodeSelector:
        {{- toYaml .Values.networkTuning.nodeSelector | nindent 8 }}
      {{- end }}
      # Host network required to modify host sysctl settings
      hostNetwork: true
      hostPID: true
      # Init container applies the sysctl settings once at pod startup
      initContainers:
        - name: apply-sysctl
          image: busybox:1.36
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add:
                - SYS_ADMIN
                - NET_ADMIN
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "Applying Tavana network performance tuning..."
              
              # ============= TCP Congestion Control =============
              # BBR (Bottleneck Bandwidth and RTT) congestion control
              # Developed by Google, included in Linux 4.9+
              # Provides significant performance gains on lossy/high-latency networks
              
              # Check if BBR is available
              if grep -q bbr /proc/sys/net/ipv4/tcp_available_congestion_control; then
                echo "Enabling TCP BBR congestion control..."
                sysctl -w net.ipv4.tcp_congestion_control={{ .Values.networkTuning.tcpCongestionControl | default "bbr" }}
                echo "TCP congestion control set to: $(cat /proc/sys/net/ipv4/tcp_congestion_control)"
              else
                echo "WARNING: BBR not available in kernel, using $(cat /proc/sys/net/ipv4/tcp_congestion_control)"
              fi
              
              # ============= TCP Buffer Sizes =============
              # For 10G networks, ESnet recommends 32-64MB buffers per socket
              # Format: min default max (in bytes)
              
              # TCP receive buffer: 4KB min, 128KB default, {{ .Values.networkTuning.tcpRmemMaxMB | default 64 }}MB max
              RMEM_MAX={{ mul (mul (.Values.networkTuning.tcpRmemMaxMB | default 64) 1024) 1024 }}
              sysctl -w net.ipv4.tcp_rmem="4096 131072 ${RMEM_MAX}"
              sysctl -w net.core.rmem_max=${RMEM_MAX}
              sysctl -w net.core.rmem_default=131072
              
              # TCP send buffer: 4KB min, 64KB default, {{ .Values.networkTuning.tcpWmemMaxMB | default 64 }}MB max
              WMEM_MAX={{ mul (mul (.Values.networkTuning.tcpWmemMaxMB | default 64) 1024) 1024 }}
              sysctl -w net.ipv4.tcp_wmem="4096 65536 ${WMEM_MAX}"
              sysctl -w net.core.wmem_max=${WMEM_MAX}
              sysctl -w net.core.wmem_default=65536
              
              # ============= Connection Handling =============
              # Increase socket backlog for high-connection scenarios
              sysctl -w net.core.somaxconn={{ .Values.networkTuning.somaxconn | default 65535 }}
              sysctl -w net.core.netdev_max_backlog={{ .Values.networkTuning.netdevMaxBacklog | default 65535 }}
              sysctl -w net.ipv4.tcp_max_syn_backlog={{ .Values.networkTuning.tcpMaxSynBacklog | default 65535 }}
              
              # ============= TCP Performance Options =============
              # Enable TCP Fast Open (reduces latency for new connections)
              sysctl -w net.ipv4.tcp_fastopen={{ .Values.networkTuning.tcpFastOpen | default 3 }}
              
              # Disable slow start after idle (keeps cwnd high)
              sysctl -w net.ipv4.tcp_slow_start_after_idle=0
              
              # Enable MTU probing for path MTU discovery
              sysctl -w net.ipv4.tcp_mtu_probing={{ .Values.networkTuning.tcpMtuProbing | default 1 }}
              
              # Increase local port range for outbound connections
              sysctl -w net.ipv4.ip_local_port_range="1024 65535"
              
              # Reuse TIME_WAIT sockets for new connections (safe for most workloads)
              sysctl -w net.ipv4.tcp_tw_reuse={{ if .Values.networkTuning.tcpTwReuse }}1{{ else }}0{{ end }}
              
              # Reduce TIME_WAIT duration (default 60s may be too long)
              sysctl -w net.ipv4.tcp_fin_timeout={{ .Values.networkTuning.tcpFinTimeout | default 15 }}
              
              # ============= Memory Pressure Handling =============
              # TCP memory limits (min pressure max) in pages (4KB each)
              # Increase for high-connection servers
              sysctl -w net.ipv4.tcp_mem="786432 1048576 1572864"
              
              # ============= Keepalive Settings =============
              # More aggressive keepalive for faster detection of dead connections
              sysctl -w net.ipv4.tcp_keepalive_time={{ .Values.networkTuning.tcpKeepaliveTime | default 60 }}
              sysctl -w net.ipv4.tcp_keepalive_intvl={{ .Values.networkTuning.tcpKeepaliveIntvl | default 10 }}
              sysctl -w net.ipv4.tcp_keepalive_probes={{ .Values.networkTuning.tcpKeepaliveProbes | default 6 }}
              
              echo "Network tuning applied successfully!"
              echo "Summary:"
              echo "  TCP congestion: $(cat /proc/sys/net/ipv4/tcp_congestion_control)"
              echo "  TCP rmem max: $(cat /proc/sys/net/core/rmem_max) bytes"
              echo "  TCP wmem max: $(cat /proc/sys/net/core/wmem_max) bytes"
              echo "  somaxconn: $(cat /proc/sys/net/core/somaxconn)"
              echo "  TCP Fast Open: $(cat /proc/sys/net/ipv4/tcp_fastopen)"
          volumeMounts:
            - name: sys
              mountPath: /proc/sys
              readOnly: false
      containers:
        # Main container just sleeps - sysctl settings persist on the host
        - name: pause
          image: busybox:1.36
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              echo "Network tuning applied. Sleeping to keep DaemonSet running..."
              # Periodically log status
              while true; do
                sleep 3600
                echo "Network tuning still active. TCP congestion: $(cat /proc/sys/net/ipv4/tcp_congestion_control)"
              done
          resources:
            requests:
              cpu: "1m"
              memory: "4Mi"
            limits:
              cpu: "10m"
              memory: "16Mi"
          securityContext:
            readOnlyRootFilesystem: true
            runAsNonRoot: false
            runAsUser: 0
      volumes:
        - name: sys
          hostPath:
            path: /proc/sys
            type: Directory
      terminationGracePeriodSeconds: 5
{{- end }}
